---
author: "Phong Duong - 100500507"
title: "Data Science II - Assignment"
output: html_document
---

```{r include = FALSE}
knitr::opts_chunk$set(warning = FALSE)
```

# Loading packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyverse)
library(DataExplorer)
library(corrplot)
library(glmnet)
library(caret) 
library(Metrics)
library(e1071)
library(pROC)
```

# Problem description

In our cities, there are some services that are essential for our daily living: **pharmacies, schools or transport points of sale.** However, these facilities are not necessarily well distributed. We want to analyze in this assignment which areas lacks of these facilities based on regression models. The steps to perform the analysis are:

-   Do a descriptive analysis of data
-   Are there variables we can discard?
-   Perform a feature engineering process extending important variables.
-   Perform regression modelling for the three target variables (three different models).
-   Create a score to measure **which areas** have enough facilities and which ones don't.
-   Which variables are the most highly related to the score? In particular, what makes a census section to have a low number of facilities?
-   Visualize and discuss the results

# Dataset description

```{r}
df<-fread("census_section_stats.csv", sep=";", dec=",", stringsAsFactors = F)
head(df)
```

For every census section we have a row in our dataset, here are some of the main columns of the dataset: \* census_section_code: census_section_code identifier \* n_pharmacies (target variable 1): number of pharmacies in the census section \* n_schools (target variable 2): number of schools in the census section \* n_transport_salespoints: number of transport points of sale.

# Descriptive analysis

## Data Exploration

### Brief Check of overall data

```{r}
str(df)
summary(df)
```

No missing data (NA)

```{r}
#Convert to appropriate data type
df <- df %>% 
  mutate(
    census_section_code = as.character(census_section_code),
    census_district_code = as.character(census_district_code),
    city_code = as.character(city_code),
    province_code = as.character(province_code)
  ) %>% #Extracting latitude and longitude from centroid
  mutate(centroid = str_extract_all(centroid, "\\d+.\\d+")) %>% 
  unnest_wider(col = c(centroid), names_sep = "_") %>% 
  rename(lat = centroid_1, long = centroid_2) %>% 
  mutate(lat = as.numeric(lat), long = as.numeric(long))

```

### **Target variables**

-   Pharmacy - each census on average has 1 pharmacy, max = 5 --\> check if income affects this

-   School - each census has around 1 school, max = 12 --\> check these high values

-   transport - seems like many censuses lack sales points --\> geography might affect this?

```{r}
target_vars <- df %>% 
  select(n_pharmacies, n_schools, n_transport_salespoints)

summary(target_vars)
```

The average number of **pharmacies** in each census is 0.66 (median = 1) with range of 0 to 5. The average number of **schools** in each census is 0.91 (median = 0) and there are anywhere between 0 and 12 school in the censuses. The average number of number of **transport POS** is 0.27 (median = 0) and range from 0 to 4.

It seems that about 50% of the censuses lack a pharmacy, school, and transport sales point, meaning that people living in these censuses would have to go to another location to get access to these services. Some censuses, however, have an excess of facilities.

```{r}
plot_histogram(target_vars)
```

From the plots, we can see that most censuses have 0 to 2 pharmacies in the area, 0 to 4 schools, and 0 to 1 transport POS.

The graph strongly indicate that some censuses might be lacking facilities in their areas. We will continue to explore the data set to identify possible variables contributing to this lack of facilities.

It is also noted that all 3 graphs are skewed to the right, suggesting that the distribution of facilities are not normal. Since the variables are discreet and non-negative, a poisson regression might be a good fit for the model. We can check the first assumption (equidispersion) to see if it's a potential fit.

```{r}
data.frame(
  mean = c(mean(df$n_pharmacies), mean(df$n_schools), mean(df$n_transport_salespoints)),
  var = c(var(df$n_pharmacies), var(df$n_schools), var(df$n_transport_salespoints)),
  row.names = c("pharmacy", "school", "transport")
)
```

It seems that the target variables have similar mean and variance, this could indicate a call for poisson regression model. Although school has variance \> mean, which is case of overdispersion, we can still use different methods to improve the model such as a Quasi-poisson Regression.

### Numerical Data

```{r}
df_num <- df %>% 
  select(where(is.numeric)) %>% 
  select(-index)
```

```{r}
#histogram
plot_histogram(df_num)
```

It is noted that different censuses seem to have different concentration of age, income, population, and foreigners - spaniards percentage. These might be important factors influencing the number of facilities in each census.

### Bivariate Analysis

```{r}
plot_boxplot(df_num, by = "n_pharmacies")
```

```{r}
plot_boxplot(df_num, by = "n_schools")
```

```{r}
plot_boxplot(df_num, by = "n_transport_salespoints")
```

With lots of predictors in the data set it is difficult to understand all of them and their relations to our response variables. We will instead check them with correlation analysis.

### Correlation Analysis

```{r}
#Correlation Matrix
cor_matrix <- cor(df_num)

findCorrelation(
  cor_matrix,
  cutoff = 0.6,
  verbose = T,
  names = T,
  exact = T
)
```

It seems that a couple of variables are correlated to each other, which might create a problem (multicolinearity) when we run the model so we should consider removing some of them for better model performance.

### Zero Variance Variables

```{r}
nearZeroVar(df, saveMetrics = TRUE) %>% filter(nzv == TRUE | zeroVar == TRUE)
```

It seems that province code only has 1 value for all observations and pcg_num_transaction_city has a very low variance. We will check them to see if we should remove them since they might not offer much help to our model.

## Feature selection

#### Checking features with low variance and are duplicated

```{r}
df %>% distinct(province_code)
```

Province_code also only has 1 observation, therefore, it will not be useful for the model.

```{r}
df %>% distinct(pcg_num_transaction_city)
```

pcg_num_transaction_city has some variation in values so we will keep it for now since our data set is also not too big.

```{r}
cor(df$foreigners, df$pcg_foreigners)
```

Foreginers and pcg_foreigners have the same values, thus, we will only need to include one of them in the model.

#### Dimensionality Reduction

```{r}
set.seed(100507500)
elastic_p <- train(
  n_pharmacies ~., data = df_num, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )

#Columns with 0 coefs
coef0_p <- coef(elastic_p$finalModel, elastic_p$bestTune$lambda) %>% 
  as.matrix() %>% 
  data.frame() %>% 
  filter(s1 == 0) %>% 
  row.names()
coef0_p 
```

```{r}
set.seed(100507500)
elastic_s <- train(
  n_schools ~., data = df_num, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )

coef0_s <- coef(elastic_s$finalModel, elastic_s$bestTune$lambda) %>% 
  as.matrix() %>% 
  data.frame() %>% 
  filter(s1 == 0) %>% 
  row.names()
```

```{r}
set.seed(100507500)
elastic_t <- train(
  n_transport_salespoints ~., data = df_num, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )
coef0_t <- coef(elastic_t$finalModel, elastic_t$bestTune$lambda) %>% 
  as.matrix() %>% 
  data.frame() %>% 
  filter(s1 == 0) %>% 
  row.names()
coef0_t
```

#### Final Selection

```{r}
fs_p <- df_num %>% #Pharmacy
  select(-all_of(coef0_p))

fs_s <- df_num %>% #School
  select(-all_of(coef0_s))

fs_t <- df_num %>% #Transport POS
  select(-all_of(coef0_t))
```

# Feature engineering

```{r}
fe_p <- fs_p %>% 
  mutate(across(c("area":"income_per_capita", "city_population", "population_density"),~.x**2,.names = "{.col}_2")) %>% 
  mutate(across(c("area":"income_per_capita", "city_population", "population_density"),~.x**3,.names = "{.col}_3"))

fe_s <- fs_s %>% 
  mutate(across(c("area":"family_income", "city_population", "population_density"),~.x**2,.names = "{.col}_2")) %>% 
  mutate(across(c("area":"family_income", "city_population", "population_density"),~.x**3,.names = "{.col}_3"))

fe_t <- fs_t %>% 
  mutate(across(c("area","population":"income_per_capita", "city_population", "population_density"),~.x**2,.names = "{.col}_2")) %>% 
  mutate(across(c("area","population":"income_per_capita", "city_population", "population_density"),~.x**3,.names = "{.col}_3"))
```

We hypothesise that there is a cap for the incremental relationship between the predictor and the response variable, for example an increase in area could mean a higher amount of facilities but there is a max a amount of facilities that could be built due to other reasons like population density, income, etc. Essentially, the relationships of these predictors and the response variables might not be linear. Therefore, we are adding quadratic and cubic terms to help the model's performance.

# Regression models

## Splitting Dataset

```{r}
set.seed(100507500)
toTrain <- createDataPartition(fe_p$n_pharmacies, p = .80, list = FALSE)

#Pharmacy
trainData_p <- fe_p[toTrain,]
testData_p <- fe_p[-toTrain,]

#School
trainData_s <- fe_s[toTrain,]
testData_s <- fe_s[-toTrain,]

#Transport
trainData_t <- fe_t[toTrain,]
testData_t <- fe_t[-toTrain,]
```

## Baseline Model

```{r}
#Helper function
error_summary <- function(test, predict) {
  rmse <- rmse(test, predict)
  mae <- mae(test, predict)
  data.frame(
    values = c(rmse, mae),
    row.names = c("RMSE", "MAE")
  )
}
```

```{r}
error_summary(testData_p$n_pharmacies, mean(trainData_p$n_pharmacies))
```

```{r}
error_summary(testData_s$n_schools, mean(trainData_s$n_schools))
```

```{r}
error_summary(testData_t$n_transport_salespoints, mean(trainData_t$n_transport_salespoints))
```

We compute our baseline models only using the average of the target variable. These models to help us see if our regression models make a difference.

## Regression Models

### Pharmacy

```{r warning=FALSE}
set.seed(100507500)

#Train model
train_control <- trainControl(method = "cv", number = 10)

#Linear Model
lm_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData_p, 
                method = "lm", 
                trControl = train_control)

lm_fit_pharmacy

#Poisson model
poisson_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData_p,
                              method = "glm", family = "poisson",
                              trControl = train_control)
poisson_fit_pharmacy

#Quasi-Poisson
quasi_poisson_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData_p,
                              method = "glm", family = "quasi",
                              trControl = train_control)

quasi_poisson_fit_pharmacy

#Negative Binomial model
neg_bin_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData_p,
                              method = "glm.nb",
                              trControl = train_control) 
```

```{r}
#Compare model performance on trainData
results_p <- resamples(list(linear = lm_fit_pharmacy, 
                          poisson = poisson_fit_pharmacy,
                          quasi_poisson = quasi_poisson_fit_pharmacy,
                          neg_bin = neg_bin_fit_pharmacy))
summary(results_p)

bwplot(results_p, scales = list(x=list(relation="free"), y=list(relation="free")))
```

All of our models seem to be better than the baseline model (lower error and higher R squared). Although the improvement is small, we have obtained better models with better fit and will help us understand the relationship between the predictors and the response variable and make better predictions.

```{r}
# Compare models using Achaiche information criteria (AIC)
list(AIC = AIC(lm_fit_pharmacy$finalModel, 
               poisson_fit_pharmacy$finalModel, 
               quasi_poisson_fit_pharmacy$finalModel,
               neg_bin_fit_pharmacy$finalModel))
```

It seems that Quasi-poisson or Negative Binomial are better model to predict n_pharmacies basing on the AIC and the previous metrics on train set.

```{r}
#Predict on testData
test_res_p <- testData_p %>% mutate(
  pred_lm = predict(lm_fit_pharmacy, testData_p),
  pred_poisson = predict(poisson_fit_pharmacy, testData_p),
  pred_quasipoisson = predict(quasi_poisson_fit_pharmacy, testData_p),
  pred_neg_bin = predict(neg_bin_fit_pharmacy, testData_p)
)

#Compare model performance on testData
post_test_performance <- function(pred_df, tar) {
  df <- data.frame(
  model = c("lm", "poisson", "quasi_poisson", "neg_bin"),
  MAE = c(
    MAE(pred_df$pred_lm, tar),
    MAE(pred_df$pred_poisson, tar),
    MAE(pred_df$pred_quasipoisson, tar),
    MAE(pred_df$pred_quasipoisson, tar)
  ),
  RMSE = c(
    RMSE(pred_df$pred_lm, tar),
    RMSE(pred_df$pred_poisson, tar),
    RMSE(pred_df$pred_quasipoisson, tar),
    RMSE(pred_df$pred_quasipoisson, tar)
  ),
  R2 = c(
    R2(pred_df$pred_lm, tar),
    R2(pred_df$pred_poisson, tar),
    R2(pred_df$pred_quasipoisson, tar),
    R2(pred_df$pred_quasipoisson, tar)
  ))
  return(df)
  }
ptp_p <- post_test_performance(test_res_p, test_res_p$n_pharmacies)
ptp_p
```

```{r}
ptp_p %>% 
  cbind(
    MAE_train = c(mean(lm_fit_pharmacy$resample$MAE),
                  mean(poisson_fit_pharmacy$resample$MAE),
                  mean(quasi_poisson_fit_pharmacy$resample$MAE),
                  mean(neg_bin_fit_pharmacy$resample$MAE)),
    RMSE_train = c(mean(lm_fit_pharmacy$resample$RMSE),
                  mean(poisson_fit_pharmacy$resample$RMSE),
                  mean(quasi_poisson_fit_pharmacy$resample$RMSE),
                  mean(neg_bin_fit_pharmacy$resample$RMSE)),
    R2_train = c(mean(lm_fit_pharmacy$resample$Rsquared),
                  mean(poisson_fit_pharmacy$resample$Rsquared),
                  mean(quasi_poisson_fit_pharmacy$resample$Rsquared),
                  mean(neg_bin_fit_pharmacy$resample$Rsquared))
  ) %>% 
  mutate(
    MAE_diff = MAE_train - MAE,
    RMSE_diff = RMSE_train - RMSE,
    R2_diff = R2_train - R2
  ) %>% 
  select(model, contains("diff"))
```

Although Quasi poisson and NegativeBbinomial models are comparable on their performance on the test set, the difference of parameters between train set and test set of quasi poisson is less than negative binomial so it might be a better model.

We acknowledge that these models are still not the best models to our data and there are other models that could perform better. The zero-inflated poisson could be a good model since our target variable has a lot of 0 observations. However, the caret package currently does not support it so we will not use it in this analysis.

### School

```{r}
set.seed(100507500)

#Linear Model
lm_fit_school <- train(n_schools ~ ., data = trainData_s, 
                method = "lm", 
                trControl = train_control)

#Poisson model
poisson_fit_school <- train(n_schools ~ ., data = trainData_s,
                              method = "glm", family = "poisson",
                              trControl = train_control)

#Quasi-Poisson
quasi_poisson_fit_school <- train(n_schools ~ ., data = trainData_s,
                              method = "glm", family = "quasi",
                              trControl = train_control)

#Negative Binomial model
neg_bin_fit_school <- train(n_schools ~ ., data = trainData_s,
                              method = "glm.nb",
                              trControl = train_control) 
```

```{r}
#Compare model performance on trainData
results_s <- resamples(list(linear = lm_fit_school, 
                          poisson = poisson_fit_school,
                          quasi_poisson = quasi_poisson_fit_school,
                          neg_bin = neg_bin_fit_school))
summary(results_s)

bwplot(results_s, scales = list(x=list(relation="free"), y=list(relation="free")))
```

```{r}
# Compare models using Achaiche information criteria (AIC)
list(AIC = AIC(lm_fit_school$finalModel, 
               poisson_fit_school$finalModel, 
               quasi_poisson_fit_school$finalModel,
               neg_bin_fit_school$finalModel))
```

```{r}
test_res_s <- testData_s %>% mutate(
  pred_lm = predict(lm_fit_school, testData_s),
  pred_poisson = predict(poisson_fit_school, testData_s),
  pred_quasipoisson = predict(quasi_poisson_fit_school, testData_s),
  pred_neg_bin = predict(neg_bin_fit_school, testData_s)
)

ptp_s <- post_test_performance(test_res_s, test_res_s$n_schools)
ptp_s
```

```{r}
ptp_s %>% 
  cbind(
    MAE_train = c(mean(lm_fit_school$resample$MAE),
                  mean(poisson_fit_school$resample$MAE),
                  mean(quasi_poisson_fit_school$resample$MAE),
                  mean(neg_bin_fit_school$resample$MAE)),
    RMSE_train = c(mean(lm_fit_school$resample$RMSE),
                   mean(poisson_fit_school$resample$RMSE),
                   mean(quasi_poisson_fit_school$resample$RMSE),
                   mean(neg_bin_fit_school$resample$RMSE)),
    R2_train = c(mean(lm_fit_school$resample$Rsquared),
                 mean(poisson_fit_school$resample$Rsquared),
                 mean(quasi_poisson_fit_school$resample$Rsquared),
                 mean(neg_bin_fit_school$resample$Rsquared))
  ) %>% 
  mutate(
    MAE_diff = MAE_train - MAE,
    RMSE_diff = RMSE_train - RMSE,
    R2_diff = R2_train - R2
  ) %>% 
  select(model, contains("diff"))
```

Negative binomial model seems to be the most appropriate model (low error, lowest AIC).

### Transport POS

```{r}
set.seed(100507500)

#Linear Model
lm_fit_transport <- train(n_transport_salespoints ~ ., data = trainData_t, 
                           method = "lm", 
                           trControl = train_control)

# Poisson model
poisson_fit_transport <- train(n_transport_salespoints ~ ., data = trainData_t,
                                method = "glm", family = "poisson",
                                trControl = train_control)

# Quasi-Poisson
quasi_poisson_fit_transport <- train(n_transport_salespoints ~ ., data = trainData_t,
                                      method = "glm", family = "quasi",
                                      trControl = train_control)

# Negative Binomial model
neg_bin_fit_transport <- train(n_transport_salespoints ~ ., data = trainData_t,
                               method = "glm.nb",
                               trControl = train_control)
```

```{r}
#Compare model performance on trainData
results_t <- resamples(list(linear = lm_fit_transport, 
                            poisson = poisson_fit_transport,
                            quasi_poisson = quasi_poisson_fit_transport,
                            neg_bin = neg_bin_fit_transport))
summary(results_t)

bwplot(results_t, scales = list(x = list(relation = "free"), y = list(relation = "free")))
```

The range of RMSE and MAE of poisson model are strangely high, indicating it might not be an appropriate model. We will not consider it.

```{r}
#Compare model performance on trainData
results_t <- resamples(list(linear = lm_fit_transport, 
                            quasi_poisson = quasi_poisson_fit_transport,
                            neg_bin = neg_bin_fit_transport))
summary(results_t)

bwplot(results_t, scales = list(x = list(relation = "free"), y = list(relation = "free")))
```

```{r}
# Compare models using Achaiche information criteria (AIC)
list(AIC = AIC(lm_fit_transport$finalModel, 
               poisson_fit_transport$finalModel, 
               quasi_poisson_fit_transport$finalModel,
               neg_bin_fit_transport$finalModel))
```

```{r}
test_res_t <- testData_t %>% mutate(
  pred_lm = predict(lm_fit_transport, testData_t),
  pred_poisson = predict(poisson_fit_transport, testData_t),
  pred_quasipoisson = predict(quasi_poisson_fit_transport, testData_t),
  pred_neg_bin = predict(neg_bin_fit_transport, testData_t)
)

ptp_t <- post_test_performance(test_res_t, test_res_t$n_transport_salespoints)
ptp_t
```

```{r}
ptp_t %>% 
  cbind(
    MAE_train = c(mean(lm_fit_transport$resample$MAE),
                  mean(poisson_fit_transport$resample$MAE),
                  mean(quasi_poisson_fit_transport$resample$MAE),
                  mean(neg_bin_fit_transport$resample$MAE, na.rm=T)),
    RMSE_train = c(mean(lm_fit_transport$resample$RMSE),
                   mean(poisson_fit_transport$resample$RMSE),
                   mean(quasi_poisson_fit_transport$resample$RMSE),
                   mean(neg_bin_fit_transport$resample$RMSE, na.rm=T)),
    R2_train = c(mean(lm_fit_transport$resample$Rsquared),
                 mean(poisson_fit_transport$resample$Rsquared),
                 mean(quasi_poisson_fit_transport$resample$Rsquared),
                 mean(neg_bin_fit_transport$resample$Rsquared, na.rm=T))
  ) %>% 
  mutate(
    MAE_diff = MAE_train - MAE,
    RMSE_diff = RMSE_train - RMSE,
    R2_diff = R2_train - R2
  ) %>% 
  select(model, contains("diff"))
```

Quasi-poisson or Negative Binomial seems to be an apt model. Since we ran into problems while training the Negative Binomial (some folds have NAs) we will use quasi-poisson instead.

## Score generation

```{r}
#Train on whole data set
#Pharmacy
finalModel_p <- train(n_pharmacies ~ ., data = fe_p,
                              method = "glm", family = "quasi",
                              trControl = train_control)
#School
finalModel_s <- train(n_schools ~ ., data = fe_s,
                              method = "glm.nb",
                              trControl = train_control)
#Transport
finalModel_t <- train(n_transport_salespoints ~ ., data = fe_t,
                                      method = "glm", family = "quasi",
                                      trControl = train_control)
```

```{r}
#Final predictions
finalPred_p <- predict(finalModel_p, fe_p) %>% as.vector()
finalPred_s <- predict(finalModel_s, fe_s) %>% as.vector()
finalPred_t <- predict(finalModel_t, fe_t) %>% as.vector()
```

```{r}
#Score generation
score_df <- df_num %>% 
  mutate(score_pharmacy = floor(finalPred_p),
         score_school = floor(finalPred_s),
         score_transport = floor(finalPred_t),
         lack_facilities = ifelse(score_pharmacy > n_pharmacies|
                                    score_school > n_schools |
                                    score_transport > n_transport_salespoints,
                                  "Yes",
                                  "No")) %>% 
  mutate(lack_facilities = as.factor(lack_facilities))
```

```{r}
#Split data
set.seed(100507500)

fs <- score_df %>% select(-contains("n_"), -contains("score_"))

toTrain_C <- createDataPartition(fs$lack_facilities, p =0.8, list=F)

trainData <- fs[toTrain_C,]
testData <- fs[-toTrain_C,]
```

```{r}
logReg <- train(lack_facilities ~., data = trainData,
                method = "glm", family = "binomial",
                trControl = train_control)

#Predictions
pred <- predict(logReg, testData, type = "prob")
predClass <- ifelse(pred$Yes > 0.3, "Yes", "No") %>% as.factor()
# Model accuracy
mean(predClass == testData$lack_facilities)
```

We want to increase sensitivity for the model since we want to be able to predict censuses that are actually lacking the facilities so we use 0.3 for the threshold.

```{r}
confusionMatrix(testData$lack_facilities, predClass, positive = "Yes")
```

```{r}
getTrainPerf(logReg)
roc(testData$lack_facilities, factor(predClass, ordered = T))
```

Although the AUC is only moderate, indicating this might not be the best model but we will use it for this problem.

```{r}
#Train on all data
set.seed(100507500)
logReg_final <- train(lack_facilities ~., data = fs,
                method = "glm", family = "binomial",
                trControl = train_control)

summary(logReg_final)
```

```{r}
#Sorted list of sum of absolute coefficients of variables
varImp(logReg_final, scale = F)
```

```{r}
predClassFinal <- predict(logReg_final, df, type = "raw")

df_final <- df %>% 
  mutate(lack_facilities_pred = predClassFinal)
```

# Result analysis and visualization

From the descriptive analysis, we see that our target variables are not evenly distributed throughout the censuses. Some censuses have 0 facilities while some area have an excessive amount compared to the average. This could have been due to the distribution in population as some areas are more populated and therfore might need more facilities.

We then conducted that correlation analysis and learned that some variables correlated to each other so multicolinearity was a potential issue and we would need to remove some variables in order to enhance the model's performance. We also did a zero variance analysis to check for variables with low to 0 variance so we could eliminate them from the data set since they would not offer any useful information to the model.

We selected the features after removing the duplicated and low variance variables, then further reduced the dimension of the data set using an ElasticNet model. In our case, the selected model had an alpha = 1 so the model is essentially a Lasso Regression model. For each of the target variable, we obtained different dimension reduction results and we created 3 different data frames for each of the target variable according to these results.

After training different models and compared their performance on train set and test set, we saw that they were not exactly the most appropriate models (with low R2 and little improvement on the fitness compared the baseline model). It is probably that our predictors and response variables do not follow a linear relationship, which our models are based on, therefore the models could not perform well. For more accurate results, we should consider other models.

Acknowledging these limitations, we continued with the best models out of the ones that we trained (Quasi-poisson Regression for n_pharmacies and n_transport_salespoints, Negative Binomial Regression for n_schools). Using these models to make prediction on the entire dataset, we obtained a score to decide whether a census lacks facilities ("Yes" for censuses with actual values \< predicted values in any of the 3 target variables). Finally, we then trained a Logistic Regression model to classify whether the lack the facilities or not. This helped us find out that the top variables related to the lack of facilities are population and certain percentage of certain nationality groups, along with the area, home expense, average age, and position of the census (longitude). Although, none of them are key indicators with strong influence on whether the census lacks facilities (low aggregated absolute coefficient). We can visualise the top 10 most important variables on a scale from 0 to 100 below.

```{r}
plot(varImp(logReg_final), top = 10)
```

Population seems to be the better indicator than others. This is logical as more bigger population might need more facilities, creating a higher demand. Other nationality variables might also be noteworthy. We can look into whether the censuses with high population of these nationalities do not have sustainable income or isolated from the community, etc. to find solutions that could help them overcome these issues.

It is also noted that the performance of the Logistic Regression model is moderate and there might be more models that could perform better. We can also further divide the censuses to different types (lacking 1 facility, lacking 2 facilities, lacking all 3, or lacking pharmacies, lacking pharmacies and schools, etc.). For this type of problem, we would need to use a model such as multinomial classification to make the predictions.

Using the Logistic Regression model, we made final predictions on the original data set to obtain an estimate of which censuses are in need of more facilities. Although the number is relatively small, these facilities are essential and hence should be adequately provided to all censuses. Below is a map showing censuses that might be lacking facilities.

```{r}
library(sf)
map <- st_as_sf(df_final, wkt = "geometry")

ggplot(data = map) +
  geom_sf(aes(fill = lack_facilities_pred),
          lwd = 0.2,
          color = "grey60") +
  scale_fill_manual(values = c("grey85", "red3")) +
  labs(
    fill = "Census lacking facilities",
    title = "Map of censuses with low facilities",
    subtitle = "(Madrid)"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 16, face = "bold")
  )
```

In order to improve the access to facilities, we can further analyse the data of these censuses with close attention to the variables mentioned above.
