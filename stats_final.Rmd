---
author: "Phong Duong - 100500507"
title: "Data Science II - Assignment"
output: html_document
---

# Loading packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyverse)
library(DataExplorer)
library(corrplot)
library(glmnet)
library(caret) 
library(Metrics)
#library(MASS) #Conflict with dplyr
library(e1071)
```

# Problem description

In our cities, there are some services that are essential for our daily living: **pharmacies, schools or transport points of sale.** However, these facilities are not necessarily well distributed. We want to analyze in this assignment which areas lacks of these facilities based on regression models. The steps to perform the analysis are:

-   Do a descriptive analysis of data
-   Are there variables we can discard?
-   Perform a feature engineering process extending important variables.
-   Perform regression modelling for the three target variables (three different models).
-   Create a score to measure **which areas** have enough facilities and which ones don't.
-   Which variables are the most highly related to the score? In particular, what makes a census section to have a low number of facilities?
-   Visualize and discuss the results

# Dataset description

```{r}
df<-fread("census_section_stats.csv", sep=";", dec=",", stringsAsFactors = F)
head(df)
```

For every census section we have a row in our dataset, here are some of the main columns of the dataset: \* census_section_code: census_section_code identifier \* n_pharmacies (target variable 1): number of pharmacies in the census section \* n_schools (target variable 2): number of schools in the census section \* n_transport_salespoints: number of transport points of sale.

# Descriptive analysis

## Data Exploration

### Brief Check of overall data

```{r}
str(df)
summary(df)
```

No missing data (NA)

```{r}
#Convert to appropriate data type
df <- df %>% 
  mutate(
    census_section_code = as.character(census_section_code),
    census_district_code = as.character(census_district_code),
    city_code = as.character(city_code),
    province_code = as.character(province_code)
  ) %>% #Extracting latitude and longitude from centroid
  mutate(centroid = str_extract_all(centroid, "\\d+.\\d+")) %>% 
  unnest_wider(col = c(centroid), names_sep = "_") %>% 
  rename(lat = centroid_1, long = centroid_2) %>% 
  mutate(lat = as.numeric(lat), long = as.numeric(long))

```

### **Target variables**

-   Pharmacy - each census on average has 1 pharmacy, max = 5 --\> check if income affects this

-   School - each census has around 1 school, max = 12 --\> check these high values

-   transport - seems like many censuses lack sales points --\> geography might affect this?

```{r}
target_vars <- df %>% 
  select(n_pharmacies, n_schools, n_transport_salespoints)

summary(target_vars)
```

The average number of **pharmacies** in each census is 0.66 (median = 1) with range of 0 to 5. The average number of **schools** in each census is 0.91 (median = 0) and there are anywhere between 0 and 12 school in the censuses. The average number of number of **transport POS** is 0.27 (median = 0) and range from 0 to 4.

It seems that about 50% of the censuses lack a pharmacy, school, and transport sales point, meaning that people living in these censuses would have to go to another location to get access to these services. Some censuses, however, have an excess of facilities.

```{r}
plot_histogram(target_vars)
```

From the plots, we can see that most censuses have 0 to 2 pharmacies in the area, 0 to 4 schools, and 0 to 1 transport POS.

The graph strongly indicate that some censuses might be lacking facilities in their areas. We will continue to explore the data set to identify possible variables contributing to this lack of facilities.

It is also noted that all 3 graphs are skewed to the right, suggesting that the distribution of facilities are not normal. Since the variables are discreet and non-negative, a poisson regression might be a good fit for the model. We can check the first assumption (equidispersion) to see if it's a potential fit.

```{r}
data.frame(
  mean = c(mean(df$n_pharmacies), mean(df$n_schools), mean(df$n_transport_salespoints)),
  var = c(var(df$n_pharmacies), var(df$n_schools), var(df$n_transport_salespoints)),
  row.names = c("pharmacy", "school", "transport")
)
```

It seems that the target variables have similar mean and variance, this could indicate a call for poisson regression model. Although school has variance \> mean, which is case of overdispersion, we can still use different methods to improve the model such as a Quasi-poisson Regression.

### Numerical Data

```{r}
df_num <- df %>% 
  select(where(is.numeric)) %>% 
  select(-index)
```

```{r}
#histogram
plot_histogram(df_num)
```

It is noted that different censuses seem to have different concentration of age, income, population, and foreigners - spaniards percentage. These might be important factors influencing the number of facilities in each census.

### Bivariate Analysis

```{r}
plot_boxplot(df_num, by = "n_pharmacies")
```

```{r}
plot_boxplot(df_num, by = "n_schools")
```

```{r}
plot_boxplot(df_num, by = "n_transport_salespoints")
```

### Correlation Analysis

```{r}
#Correlation Matrix
cor_matrix <- cor(df_num)

findCorrelation(
  cor_matrix,
  cutoff = 0.6,
  verbose = T,
  names = T,
  exact = T
)
```

It seems that a couple of variables are correlated to each other, which might create a problem (multicolinearity) when we run the model so we should consider removing some of them for better model performance.

### Zero Variance Variables

```{r}
nearZeroVar(df, saveMetrics = TRUE) %>% filter(nzv == TRUE | zeroVar == TRUE)
```

It seems that province code only has 1 value for all observations and pcg_num_transaction_city has a very low variance. We will check them to see if we should remove them since they might not offer much help to our model.

## Feature selection

#### Checking features with low variance and are duplicated

```{r}
df %>% distinct(province_code)
```

Province_code also only has 1 observation, therefore, it will not be useful for the model.

```{r}
df %>% distinct(pcg_num_transaction_city)
```

pcg_num_transaction_city has some variation in values so we will keep it for now.

```{r}
cor(df$foreigners, df$pcg_foreigners)
```

Foreginers and pcg_foreigners have the same values, thus, we will only need to include one of them in the model.

#### Dimensionality Reduction

```{r}
set.seed(100507500)
elastic_p <- train(
  n_pharmacies ~., data = df_num, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )

#Columns with 0 coefs
coef0_p <- coef(elastic_p$finalModel, elastic_p$bestTune$lambda) %>% 
  as.matrix() %>% 
  data.frame() %>% 
  filter(s1 == 0) %>% 
  row.names()
coef0_p 
```

```{r}
set.seed(100507500)
elastic_s <- train(
  n_schools ~., data = df_num, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )

coef0_s <- coef(elastic_s$finalModel, elastic_s$bestTune$lambda) %>% 
  as.matrix() %>% 
  data.frame() %>% 
  filter(s1 == 0) %>% 
  row.names()
```

```{r}
set.seed(100507500)
elastic_t <- train(
  n_transport_salespoints ~., data = df_num, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )
coef0_t <- coef(elastic_t$finalModel, elastic_t$bestTune$lambda) %>% 
  as.matrix() %>% 
  data.frame() %>% 
  filter(s1 == 0) %>% 
  row.names()
coef0_t
```

#### Final Selection

```{r}
fs_p <- df_num %>% 
  select(-all_of(coef0_p))

fs_s <- df_num %>% 
  select(-all_of(coef0_s))

fs_t <- df_num %>% 
  select(-all_of(coef0_t))
```

# Feature engineering

```{r}
fe_df <- selected_features %>% 
  mutate(
    population_2 = population**2,
    population_density_2 = population_density**2,
    city_population_2 = city_population**2,
    family_income_2 = family_income**2,
    income_per_capita_2 = income_per_capita**2,
    avg_age_2 = avg_age**2,
    foreigners_2 = foreigners**2
  )

fe_p <- fs_p %>% 
  mutate(across(c("area":"income_per_capita", "city_population", "population_density"),~.x**2,.names = "{.col}_2")) %>% 
  mutate(across(c("area":"income_per_capita", "city_population", "population_density"),~.x**3,.names = "{.col}_3"))

fe_s <- fs_s %>% 
  mutate(across(c("area":"family_income", "city_population", "population_density"),~.x**2,.names = "{.col}_2")) %>% 
  mutate(across(c("area":"family_income", "city_population", "population_density"),~.x**3,.names = "{.col}_3"))

fe_t <- fs_t %>% 
  mutate(across(c("area","population":"income_per_capita", "city_population", "population_density"),~.x**2,.names = "{.col}_2")) %>% 
  mutate(across(c("area","population":"income_per_capita", "city_population", "population_density"),~.x**3,.names = "{.col}_3"))
```

We hypothesise that there is a cap for the incremental relationship between the predictor and the response variable, for example an increase in area could mean a higher amount of facilities but there is a max a amount of facilities that could be built due to other reasons like population density, income, etc. Therefore, we are adding quadratic and cubic terms to help the model performance.

# Regression models

## Splitting Dataset

```{r}
set.seed(100507500)
toTrain <- createDataPartition(fe_p$n_pharmacies, p = .80, list = FALSE)

#Pharmacy
trainData_p <- fe_p[toTrain,]
testData_p <- fe_p[-toTrain,]

#School
trainData_s <- fe_s[toTrain,]
testData_s <- fe_s[-toTrain,]

#Transport
trainData_t <- fe_t[toTrain,]
testData_t <- fe_t[-toTrain,]
```

## Baseline Model

```{r}
#Helper function
error_summary <- function(test, predict) {
  rmse <- rmse(test, predict)
  mae <- mae(test, predict)
  data.frame(
    values = c(rmse, mae),
    row.names = c("RMSE", "MAE")
  )
}
```

```{r}
error_summary(testData_p$n_pharmacies, mean(trainData_p$n_pharmacies))
```

```{r}
error_summary(testData_s$n_schools, mean(trainData_s$n_schools))
```

```{r}
error_summary(testData_t$n_transport_salespoints, mean(trainData_t$n_transport_salespoints))
```

## Regression Models

### Pharmacy

```{r}
set.seed(100507500)

#Train model
train_control <- trainControl(method = "cv", number = 10)

#Linear Model
lm_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData_p, 
                method = "lm", 
                trControl = train_control)

lm_fit_pharmacy

#Poisson model
poisson_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData_p,
                              method = "glm", family = "poisson",
                              trControl = train_control)
poisson_fit_pharmacy

#Quasi-Poisson
quasi_poisson_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData_p,
                              method = "glm", family = "quasi",
                              trControl = train_control)

quasi_poisson_fit_pharmacy

#Negative Binomial model
neg_bin_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData_p,
                              method = "glm.nb",
                              trControl = train_control) 
```

```{r}
#Compare model performance on trainData
results_p <- resamples(list(linear = lm_fit_pharmacy, 
                          poisson = poisson_fit_pharmacy,
                          quasi_poisson = quasi_poisson_fit_pharmacy,
                          neg_bin = neg_bin_fit_pharmacy))
summary(results_p)

bwplot(results_p, scales = list(x=list(relation="free"), y=list(relation="free")))
```

On train data, lm performs better than the rest.

```{r}
# Compare models using Achaiche information criteria (AIC)
list(AIC = AIC(lm_fit_pharmacy$finalModel, 
               poisson_fit_pharmacy$finalModel, 
               quasi_poisson_fit_pharmacy$finalModel,
               neg_bin_fit_pharmacy$finalModel))
```

```{r}
#Predict on testData
test_res_p <- testData_p %>% mutate(
  pred_lm = predict(lm_fit_pharmacy, testData_p),
  pred_poisson = predict(poisson_fit_pharmacy, testData_p),
  pred_quasipoisson = predict(quasi_poisson_fit_pharmacy, testData_p),
  pred_neg_bin = predict(neg_bin_fit_pharmacy, testData_p)
)

#Compare model performance on testData
post_test_performance <- function(pred_df, tar) {
  df <- data.frame(
  model = c("lm", "poisson", "quasi_poisson", "neg_bin"),
  MAE = c(
    MAE(pred_df$pred_lm, tar),
    MAE(pred_df$pred_poisson, tar),
    MAE(pred_df$pred_quasipoisson, tar),
    MAE(pred_df$pred_quasipoisson, tar)
  ),
  RMSE = c(
    RMSE(pred_df$pred_lm, tar),
    RMSE(pred_df$pred_poisson, tar),
    RMSE(pred_df$pred_quasipoisson, tar),
    RMSE(pred_df$pred_quasipoisson, tar)
  ),
  R2 = c(
    R2(pred_df$pred_lm, tar),
    R2(pred_df$pred_poisson, tar),
    R2(pred_df$pred_quasipoisson, tar),
    R2(pred_df$pred_quasipoisson, tar)
  ))
  return(df)
  }
ptp_p <- post_test_performance(test_res_p, test_res_p$n_pharmacies)
ptp_p
```

```{r}
ptp_p %>% 
  cbind(
    MAE_train = c(mean(lm_fit_pharmacy$resample$MAE),
                  mean(poisson_fit_pharmacy$resample$MAE),
                  mean(quasi_poisson_fit_pharmacy$resample$MAE),
                  mean(neg_bin_fit_pharmacy$resample$MAE)),
    RMSE_train = c(mean(lm_fit_pharmacy$resample$RMSE),
                  mean(poisson_fit_pharmacy$resample$RMSE),
                  mean(quasi_poisson_fit_pharmacy$resample$RMSE),
                  mean(neg_bin_fit_pharmacy$resample$RMSE)),
    R2_train = c(mean(lm_fit_pharmacy$resample$Rsquared),
                  mean(poisson_fit_pharmacy$resample$Rsquared),
                  mean(quasi_poisson_fit_pharmacy$resample$Rsquared),
                  mean(neg_bin_fit_pharmacy$resample$Rsquared))
  ) %>% 
  mutate(
    MAE_diff = MAE_train - MAE,
    RMSE_diff = RMSE_train - RMSE,
    R2_diff = R2_train - R2
  ) %>% 
  select(model, contains("diff"))
```

Although quasi poisson and negative binominal models are comparable on their performance on the test set, the difference of parameters between train set and test set of quasi poisson is less than negative binomial so it might be a better model.

### School

```{r}
set.seed(100507500)

#Linear Model
lm_fit_school <- train(n_schools ~ ., data = trainData_s, 
                method = "lm", 
                trControl = train_control)

#Poisson model
poisson_fit_school <- train(n_schools ~ ., data = trainData_s,
                              method = "glm", family = "poisson",
                              trControl = train_control)

#Quasi-Poisson
quasi_poisson_fit_school <- train(n_schools ~ ., data = trainData_s,
                              method = "glm", family = "quasi",
                              trControl = train_control)

#Negative Binomial model
neg_bin_fit_school <- train(n_schools ~ ., data = trainData_s,
                              method = "glm.nb",
                              trControl = train_control) 
```

```{r}
#Compare model performance on trainData
results_s <- resamples(list(linear = lm_fit_school, 
                          poisson = poisson_fit_school,
                          quasi_poisson = quasi_poisson_fit_school,
                          neg_bin = neg_bin_fit_school))
summary(results_s)

bwplot(results_s, scales = list(x=list(relation="free"), y=list(relation="free")))
```

```{r}
# Compare models using Achaiche information criteria (AIC)
list(AIC = AIC(lm_fit_school$finalModel, 
               poisson_fit_school$finalModel, 
               quasi_poisson_fit_school$finalModel,
               neg_bin_fit_school$finalModel))
```

```{r}
test_res_s <- testData_s %>% mutate(
  pred_lm = predict(lm_fit_school, testData_s),
  pred_poisson = predict(poisson_fit_school, testData_s),
  pred_quasipoisson = predict(quasi_poisson_fit_school, testData_s),
  pred_neg_bin = predict(neg_bin_fit_school, testData_s)
)

ptp_s <- post_test_performance(test_res_s, test_res_s$n_schools)
ptp_s
```

```{r}
ptp_s %>% 
  cbind(
    MAE_train = c(mean(lm_fit_school$resample$MAE),
                  mean(poisson_fit_school$resample$MAE),
                  mean(quasi_poisson_fit_school$resample$MAE),
                  mean(neg_bin_fit_school$resample$MAE)),
    RMSE_train = c(mean(lm_fit_school$resample$RMSE),
                   mean(poisson_fit_school$resample$RMSE),
                   mean(quasi_poisson_fit_school$resample$RMSE),
                   mean(neg_bin_fit_school$resample$RMSE)),
    R2_train = c(mean(lm_fit_school$resample$Rsquared),
                 mean(poisson_fit_school$resample$Rsquared),
                 mean(quasi_poisson_fit_school$resample$Rsquared),
                 mean(neg_bin_fit_school$resample$Rsquared))
  ) %>% 
  mutate(
    MAE_diff = MAE_train - MAE,
    RMSE_diff = RMSE_train - RMSE,
    R2_diff = R2_train - R2
  ) %>% 
  select(model, contains("diff"))
```

Negative binomial model seems to be the most appropriate model (low error, lowest AIC).

### Transport POS

```{r}
set.seed(100507500)

#Linear Model
lm_fit_transport <- train(n_transport_salespoints ~ ., data = trainData_t, 
                           method = "lm", 
                           trControl = train_control)

# Poisson model
poisson_fit_transport <- train(n_transport_salespoints ~ ., data = trainData_t,
                                method = "glm", family = "poisson",
                                trControl = train_control)

# Quasi-Poisson
quasi_poisson_fit_transport <- train(n_transport_salespoints ~ ., data = trainData_t,
                                      method = "glm", family = "quasi",
                                      trControl = train_control)

# Negative Binomial model
neg_bin_fit_transport <- train(n_transport_salespoints ~ ., data = trainData_t,
                               method = "glm.nb",
                               trControl = train_control)
```

```{r}
#Compare model performance on trainData
results_t <- resamples(list(linear = lm_fit_transport, 
                            poisson = poisson_fit_transport,
                            quasi_poisson = quasi_poisson_fit_transport,
                            neg_bin = neg_bin_fit_transport))
summary(results_t)

bwplot(results_t, scales = list(x = list(relation = "free"), y = list(relation = "free")))
```

The range of RMSE and MAE of poisson model are strangely high, indicating it might not be an appropriate model. We will not consider it.

```{r}
#Compare model performance on trainData
results_t <- resamples(list(linear = lm_fit_transport, 
                            quasi_poisson = quasi_poisson_fit_transport,
                            neg_bin = neg_bin_fit_transport))
summary(results_t)

bwplot(results_t, scales = list(x = list(relation = "free"), y = list(relation = "free")))
```

```{r}
# Compare models using Achaiche information criteria (AIC)
list(AIC = AIC(lm_fit_transport$finalModel, 
               poisson_fit_transport$finalModel, 
               quasi_poisson_fit_transport$finalModel,
               neg_bin_fit_transport$finalModel))
```

```{r}
test_res_t <- testData_t %>% mutate(
  pred_lm = predict(lm_fit_transport, testData_t),
  pred_poisson = predict(poisson_fit_transport, testData_t),
  pred_quasipoisson = predict(quasi_poisson_fit_transport, testData_t),
  pred_neg_bin = predict(neg_bin_fit_transport, testData_t)
)

ptp_t <- post_test_performance(test_res_t, test_res_t$n_transport_salespoints)
ptp_t
```

```{r}
ptp_t %>% 
  cbind(
    MAE_train = c(mean(lm_fit_transport$resample$MAE),
                  mean(poisson_fit_transport$resample$MAE),
                  mean(quasi_poisson_fit_transport$resample$MAE),
                  mean(neg_bin_fit_transport$resample$MAE, na.rm=T)),
    RMSE_train = c(mean(lm_fit_transport$resample$RMSE),
                   mean(poisson_fit_transport$resample$RMSE),
                   mean(quasi_poisson_fit_transport$resample$RMSE),
                   mean(neg_bin_fit_transport$resample$RMSE, na.rm=T)),
    R2_train = c(mean(lm_fit_transport$resample$Rsquared),
                 mean(poisson_fit_transport$resample$Rsquared),
                 mean(quasi_poisson_fit_transport$resample$Rsquared),
                 mean(neg_bin_fit_transport$resample$Rsquared, na.rm=T))
  ) %>% 
  mutate(
    MAE_diff = MAE_train - MAE,
    RMSE_diff = RMSE_train - RMSE,
    R2_diff = R2_train - R2
  ) %>% 
  select(model, contains("diff"))
```

Quasi-poisson or Negative Binomial seems to be an apt model. Since we ran into problems while training the Negative Binomial (some folds have NAs) we will use quasi-poisson instead.

## Score generation

```{r}
# TO DO
```

# Result analysis and visualization

```{r}
# TO DO
```
