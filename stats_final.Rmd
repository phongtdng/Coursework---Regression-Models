---
author: "Phong Duong - 100500507"
title: "Data Science II - Assignment"
output: html_document
---

# Loading packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(tidyverse)
library(DataExplorer)
library(corrplot)
library(glmnet)
library(caret) 
library(Metrics)
#library(MASS) #Conflict with dplyr
library(e1071)
```

# Problem description

In our cities, there are some services that are essential for our daily living: **pharmacies, schools or transport points of sale.** However, these facilities are not necessarily well distributed. We want to analyze in this assignment which areas lacks of these facilities based on regression models. The steps to perform the analysis are:

-   Do a descriptive analysis of data
-   Are there variables we can discard?
-   Perform a feature engineering process extending important variables.
-   Perform regression modelling for the three target variables (three different models).
-   Create a score to measure **which areas** have enough facilities and which ones don't.
-   Which variables are the most highly related to the score? In particular, what makes a census section to have a low number of facilities?
-   Visualize and discuss the results

# Dataset description

```{r}
df<-fread("census_section_stats.csv", sep=";", dec=",", stringsAsFactors = F)
head(df)
```

For every census section we have a row in our dataset, here are some of the main columns of the dataset: \* census_section_code: census_section_code identifier \* n_pharmacies (target variable 1): number of pharmacies in the census section \* n_schools (target variable 2): number of schools in the census section \* n_transport_salespoints: number of transport points of sale.

# Descriptive analysis

## Data Exploration

### Brief Check of overall data

```{r}
str(df)
summary(df)
```

No missing data (NA)

```{r}
#Convert to appropriate data type
df <- df %>% 
  mutate(
    census_section_code = as.character(census_section_code),
    census_district_code = as.character(census_district_code),
    city_code = as.character(city_code),
    province_code = as.character(province_code)
  ) %>% #Extracting latitude and longitude from centroid
  mutate(centroid = str_extract_all(centroid, "\\d+.\\d+")) %>% 
  unnest_wider(col = c(centroid), names_sep = "_") %>% 
  rename(lat = centroid_1, long = centroid_2) %>% 
  mutate(lat = as.numeric(lat), long = as.numeric(long))

```

### **Target variables**

-   Pharmacy - each census on average has 1 pharmacy, max = 5 --\> check if income affects this

-   School - each census has around 1 school, max = 12 --\> check these high values

-   transport - seems like many censuses lack sales points --\> geography might affect this?

```{r}
target_vars <- df %>% 
  select(n_pharmacies, n_schools, n_transport_salespoints)

summary(target_vars)
```

The average number of **pharmacies** in each census is 0.66 (median = 1) with range of 0 to 5. The average number of **schools** in each census is 0.91 (median = 0) and there are anywhere between 0 and 12 school in the censuses. The average number of number of **transport POS** is 0.27 (median = 0) and range from 0 to 4.

It seems that about 50% of the censuses lack a pharmacy, school, and transport sales point, meaning that people living in these censuses would have to go to another location to get access to these services. Some censuses, however, have an excess of facilities.

```{r}
plot_histogram(target_vars)
```

From the plots, we can see that most censuses have 0 to 2 pharmacies in the area, 0 to 4 schools, and 0 to 1 transport POS.

The graph strongly indicate that some censuses might be lacking facilities in their areas. We will continue to explore the data set to identify possible variables contributing to this lack of facilities.

It is also noted that all 3 graphs are skewed to the right, suggesting that the distribution of facilities are not normal. Since the variables are discreet and non-negative, a poisson regression might be a good fit for the model. We can check the first assumption (equidispersion) to see if it's a potential fit.

```{r}
data.frame(
  mean = c(mean(df$n_pharmacies), mean(df$n_schools), mean(df$n_transport_salespoints)),
  var = c(var(df$n_pharmacies), var(df$n_schools), var(df$n_transport_salespoints)),
  row.names = c("pharmacy", "school", "transport")
)
```

It seems that the target variables have similar mean and variance, this could indicate a call for poisson regression model. Although school has variance \> mean, which is case of overdispersion, we can still use different methods to improve the model such as a Quasi-poisson Regression.

### Numerical Data

```{r}
df_num <- df %>% 
  select(where(is.numeric)) %>% 
  select(-index)
```

```{r}
#histogram
plot_histogram(df_num)
```

It is noted that different censuses seem to have different concentration of age, income, population, and foreigners - spaniards percentage. These might be important factors influencing the number of facilities in each census.

### Bivariate Analysis

```{r}
plot_boxplot(df_num, by = "n_pharmacies")
```

```{r}
plot_boxplot(df_num, by = "n_schools")
```

```{r}
plot_boxplot(df_num, by = "n_transport_salespoints")
```

### Correlation Analysis

```{r}
#Correlation Matrix
cor_matrix <- cor(df_num)

findCorrelation(
  cor_matrix,
  cutoff = 0.6,
  verbose = T,
  names = T,
  exact = T
)
```

It seems that a couple of variables are correlated to each other, which might create a problem (multicolinearity) when we run the model so we should consider removing some of them for better model performance.

### Zero Variance Variables

```{r}
nearZeroVar(df, saveMetrics = TRUE) %>% filter(nzv == TRUE | zeroVar == TRUE)
```

It seems that province code only has 1 value for all observations and pcg_num_transaction_city has a very low variance. We will check them to see if we should remove them since they might not offer much help to our model.

## Feature selection

#### Checking features with low variance and are duplicated

```{r}
df %>% distinct(province_code)
```

Province_code also only has 1 observation, therefore, it will not be useful for the model.

```{r}
df %>% distinct(pcg_num_transaction_city)
```

pcg_num_transaction_city has some variation in values so we will keep it for now.

```{r}
cor(df$foreigners, df$pcg_foreigners)
```

Foreginers and pcg_foreigners have the same values, thus, we will only need to include one of them in the model.

#### Dimensionality Reduction

```{r}
set.seed(100507500)
elastic_p <- train(
  n_pharmacies ~., data = df_num, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )

#Columns with 0 coefs
coef0_p <- coef(elastic_p$finalModel, elastic_p$bestTune$lambda) %>% 
  as.matrix() %>% 
  data.frame() %>% 
  filter(s1 == 0) %>% 
  row.names()
coef0_p 
```

```{r}
set.seed(100507500)
elastic_s <- train(
  n_schools ~., data = df_num, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )
coef(elastic_s$finalModel, elastic_s$bestTune$lambda) %>% 
  as.matrix() %>% 
  data.frame() %>% 
  filter(s1 == 0)
```

```{r}
set.seed(100507500)
elastic_t <- train(
  n_transport_salespoints ~., data = df_num, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10
  )
coef(elastic_t$finalModel, elastic_t$bestTune$lambda) %>% 
  as.matrix() %>% 
  data.frame() %>% 
  filter(s1 == 0)
```

#### Final Selection

```{r}
selected_features <- df %>% 
  select(-c(index, province_code, census_section_code, census_district_code, city_code, pcg_foreigners, geometry, centroid))

fs_p <- df_num %>% 
  select(-all_of(coef0_p))
```

# Feature engineering

```{r}
fe_df <- selected_features %>% 
  mutate(
    population_2 = population**2,
    population_density_2 = population_density**2,
    city_population_2 = city_population**2,
    family_income_2 = family_income**2,
    income_per_capita_2 = income_per_capita**2,
    avg_age_2 = avg_age**2,
    foreigners_2 = foreigners**2
  )

fe_p <- fs_p %>% 
  mutate(across(c("area":"income_per_capita", "city_population", "population_density"),~.x**2,.names = "{.col}_2")) %>% 
  mutate(across(c("area":"income_per_capita", "city_population", "population_density"),~.x**3,.names = "{.col}_3"))
```

We hypothesise that there is a cap for the incremental relationship between the predictor and the response variable, for example an increase in area could mean a higher amount of facilities but there is a max a amount of facilities that could be built due to other reasons like population density, income, etc. Therefore, we are adding quadratic and cubic terms to help the model performance.

# Regression models

## Splitting Dataset

```{r}
toTrain <- createDataPartition(fe_p$n_pharmacies, p = .80, list = FALSE)

trainData <- fe_p[toTrain,]
testData <- fe_p[-toTrain,]
```

## Baseline Model

```{r}
#Helper function
error_summary <- function(test, predict) {
  mse <- mse(test, predict)
  mae <- mae(test, predict)
  data.frame(
    values = c(mse, mae),
    row.names = c("MSE", "MAE")
  )
}
```

### Pharmacy

```{r}
error_summary(testData$n_pharmacies, mean(trainData$n_pharmacies))
```

### School

```{r}
error_summary(testData$n_schools, mean(train_b$n_schools))
```

### Transport POS

```{r}
error_summary(testData$n_transport_salespoints, mean(train_b$n_transport_salespoints))
```

## Regression Models

### Pharmacy

```{r}
set.seed(100507500)

#Train model
train_control <- trainControl(method = "cv", number = 10)

#Linear Model
lm_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData, 
                method = "lm", 
                trControl = train_control)

lm_fit_pharmacy

#Poisson model
poisson_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData,
                              method = "glm", family = "poisson",
                              trControl = train_control)
poisson_fit_pharmacy

#Quasi-Poisson
quasi_poisson_fit_pharmacy <- train(n_pharmacies ~ ., data = trainData,
                              method = "glm", family = "quasi",
                              trControl = train_control)

quasi_poisson_fit_pharmacy
```

```{r}
#Compare model performance on trainData
results <- resamples(list(linear = lm_fit_pharmacy, 
                          poisson = poisson_fit_pharmacy,
                          quasi_poisson = quasi_poisson_fit_pharmacy))
summary(results)

bwplot(results, scales = list(x=list(relation="free"), y=list(relation="free")))
```

On train data, lm performs better than the rest.

```{r}
# Compare models using Achaiche information criteria (AIC)
list(AIC = AIC(lm_fit_pharmacy$finalModel, 
               poisson_fit_pharmacy$finalModel, 
               quasi_poisson_fit_pharmacy$finalModel))
```

```{r}
#Importance variables
tibble(
  lm = rownames(varImp(lm_fit_pharmacy)$importance)[1:20],
  poisson = rownames(varImp(poisson_fit_pharmacy)$importance)[1:20],
  quasi_poisson = rownames(varImp(quasi_poisson_fit_pharmacy)$importance)[1:20]
)
```

Most important variables: area, population, family income, income per capita, average age, and spanish percentage.

```{r}
#Predict on testData
test_phar <- testData %>% mutate(
  pred_lm = predict(lm_fit_pharmacy, testData),
  pred_poisson = predict(poisson_fit_pharmacy, testData),
  pred_quasipoisson = predict(quasi_poisson_fit_pharmacy, testData)
)
test_phar %>% select(n_pharmacies,contains("pred"))
```

```{r}
#Compare model performance on testData
list(
  lm = mae(test_phar$pred_lm, test_phar$n_pharmacies),
  poisson = mae(test_phar$pred_poisson, test_phar$n_pharmacies),
  quasi_poisson = mae(test_phar$pred_quasipoisson, test_phar$n_pharmacies)
)
```

On test data, lm and quasi_poisson performs better.

### School

```{r}

```

### Transport POS

```{r}

```

## Score generation

```{r}
# TO DO
```

# Result analysis and visualization

```{r}
# TO DO
```
